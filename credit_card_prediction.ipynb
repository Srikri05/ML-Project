{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Credit Card Limit Prediction\n",
        "\n",
        "This notebook implements a machine learning model to predict credit card limits using customer data.\n",
        "\n",
        "## Dataset\n",
        "Download the dataset from: https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers\n",
        "Place the `BankChurners.csv` file in the same directory as this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load and Explore the Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('BankChurners.csv')\n",
        "\n",
        "# Basic data exploration\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset info\n",
        "print(\"Dataset info:\")\n",
        "print(df.info())\n",
        "print(\"\\nMissing values:\")\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select target and features\n",
        "y = df['Credit_Limit']\n",
        "\n",
        "# Select the specified input features\n",
        "features_to_use = [\n",
        "    'Customer_Age',\n",
        "    'Dependent_count', \n",
        "    'Education_Level',\n",
        "    'Income_Category',\n",
        "    'Months_on_book',\n",
        "    'Total_Relationship_Count',\n",
        "    'Total_Trans_Amt',\n",
        "    'Marital_Status'\n",
        "]\n",
        "\n",
        "X = df[features_to_use].copy()\n",
        "\n",
        "print(\"Selected features:\")\n",
        "print(features_to_use)\n",
        "print(f\"\\nTarget variable (Credit_Limit) range: ${y.min():,.2f} - ${y.max():,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values in selected features\n",
        "print(\"Missing values per column:\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "# Check unique values in categorical columns\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "for col in ['Education_Level', 'Income_Category', 'Marital_Status']:\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(X[col].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Handle categorical variables with ordinal encoding\n",
        "\n",
        "# Education Level encoding\n",
        "education_mapping = {\n",
        "    'Unknown': 0,\n",
        "    'Uneducated': 1,\n",
        "    'High School': 2,\n",
        "    'College': 3,\n",
        "    'Graduate': 4,\n",
        "    'Post-Graduate': 5,\n",
        "    'Doctorate': 6\n",
        "}\n",
        "X['Education_Level'] = X['Education_Level'].map(education_mapping)\n",
        "\n",
        "# Income Category encoding\n",
        "income_mapping = {\n",
        "    'Unknown': 0,\n",
        "    'Less than $40K': 1,\n",
        "    '$40K - $60K': 2,\n",
        "    '$60K - $80K': 3,\n",
        "    '$80K - $120K': 4,\n",
        "    '$120K +': 5\n",
        "}\n",
        "X['Income_Category'] = X['Income_Category'].map(income_mapping)\n",
        "\n",
        "# Marital Status encoding\n",
        "marital_mapping = {\n",
        "    'Unknown': 0,\n",
        "    'Single': 1,\n",
        "    'Married': 2,\n",
        "    'Divorced': 3\n",
        "}\n",
        "X['Marital_Status'] = X['Marital_Status'].map(marital_mapping)\n",
        "\n",
        "# Fill any NaN values that resulted from mapping\n",
        "X = X.fillna(0)\n",
        "\n",
        "print(\"Categorical encoding complete!\")\n",
        "print(\"\\nEncoded features preview:\")\n",
        "print(X.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Data split complete!\")\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n",
        "print(f\"Features: {X_train.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Implement Multiple Regression Models\n",
        "\n",
        "We'll implement all the regression methods from the reference table:\n",
        "1. Linear Regression and Polynomial Regression\n",
        "2. Ridge and Lasso Regression (with regularization)\n",
        "3. Decision Tree and Random Forest Regression\n",
        "4. Multi-layer Perceptron (Neural Network) Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all necessary regression models\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Dictionary to store all models and their results\n",
        "models = {}\n",
        "results = {}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Linear Regression and Polynomial Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Linear Regression\n",
        "print(\"Training Linear Regression...\")\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "lr_pred = lr_model.predict(X_test_scaled)\n",
        "\n",
        "models['Linear Regression'] = lr_model\n",
        "results['Linear Regression'] = {\n",
        "    'R2': r2_score(y_test, lr_pred),\n",
        "    'MSE': mean_squared_error(y_test, lr_pred),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, lr_pred)),\n",
        "    'MAE': mean_absolute_error(y_test, lr_pred)\n",
        "}\n",
        "\n",
        "print(f\"Linear Regression - R¬≤: {results['Linear Regression']['R2']:.4f}\")\n",
        "\n",
        "# 2. Polynomial Regression (degree 2)\n",
        "print(\"\\nTraining Polynomial Regression (degree 2)...\")\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly_features.fit_transform(X_train_scaled)\n",
        "X_test_poly = poly_features.transform(X_test_scaled)\n",
        "\n",
        "poly_model = LinearRegression()\n",
        "poly_model.fit(X_train_poly, y_train)\n",
        "poly_pred = poly_model.predict(X_test_poly)\n",
        "\n",
        "models['Polynomial Regression'] = (poly_model, poly_features)\n",
        "results['Polynomial Regression'] = {\n",
        "    'R2': r2_score(y_test, poly_pred),\n",
        "    'MSE': mean_squared_error(y_test, poly_pred),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, poly_pred)),\n",
        "    'MAE': mean_absolute_error(y_test, poly_pred)\n",
        "}\n",
        "\n",
        "print(f\"Polynomial Regression - R¬≤: {results['Polynomial Regression']['R2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Ridge and Lasso Regression (with regularization)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Ridge Regression (L2 regularization)\n",
        "print(\"Training Ridge Regression...\")\n",
        "ridge_model = Ridge(alpha=1.0, random_state=42)\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "ridge_pred = ridge_model.predict(X_test_scaled)\n",
        "\n",
        "models['Ridge Regression'] = ridge_model\n",
        "results['Ridge Regression'] = {\n",
        "    'R2': r2_score(y_test, ridge_pred),\n",
        "    'MSE': mean_squared_error(y_test, ridge_pred),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, ridge_pred)),\n",
        "    'MAE': mean_absolute_error(y_test, ridge_pred)\n",
        "}\n",
        "\n",
        "print(f\"Ridge Regression - R¬≤: {results['Ridge Regression']['R2']:.4f}\")\n",
        "\n",
        "# 4. Lasso Regression (L1 regularization)\n",
        "print(\"\\nTraining Lasso Regression...\")\n",
        "lasso_model = Lasso(alpha=0.1, random_state=42, max_iter=1000)\n",
        "lasso_model.fit(X_train_scaled, y_train)\n",
        "lasso_pred = lasso_model.predict(X_test_scaled)\n",
        "\n",
        "models['Lasso Regression'] = lasso_model\n",
        "results['Lasso Regression'] = {\n",
        "    'R2': r2_score(y_test, lasso_pred),\n",
        "    'MSE': mean_squared_error(y_test, lasso_pred),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, lasso_pred)),\n",
        "    'MAE': mean_absolute_error(y_test, lasso_pred)\n",
        "}\n",
        "\n",
        "print(f\"Lasso Regression - R¬≤: {results['Lasso Regression']['R2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Decision Tree and Random Forest Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Decision Tree Regression\n",
        "print(\"Training Decision Tree Regression...\")\n",
        "dt_model = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "dt_pred = dt_model.predict(X_test_scaled)\n",
        "\n",
        "models['Decision Tree'] = dt_model\n",
        "results['Decision Tree'] = {\n",
        "    'R2': r2_score(y_test, dt_pred),\n",
        "    'MSE': mean_squared_error(y_test, dt_pred),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, dt_pred)),\n",
        "    'MAE': mean_absolute_error(y_test, dt_pred)\n",
        "}\n",
        "\n",
        "print(f\"Decision Tree - R¬≤: {results['Decision Tree']['R2']:.4f}\")\n",
        "\n",
        "# 6. Random Forest Regression\n",
        "print(\"\\nTraining Random Forest Regression...\")\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "rf_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "models['Random Forest'] = rf_model\n",
        "results['Random Forest'] = {\n",
        "    'R2': r2_score(y_test, rf_pred),\n",
        "    'MSE': mean_squared_error(y_test, rf_pred),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, rf_pred)),\n",
        "    'MAE': mean_absolute_error(y_test, rf_pred)\n",
        "}\n",
        "\n",
        "print(f\"Random Forest - R¬≤: {results['Random Forest']['R2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Multi-layer Perceptron (Neural Network) Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Multi-layer Perceptron (Neural Network) Regression\n",
        "print(\"Training Multi-layer Perceptron Regression...\")\n",
        "mlp_model = MLPRegressor(\n",
        "    hidden_layer_sizes=(100, 50),  # Two hidden layers with 100 and 50 neurons\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.001,  # L2 regularization\n",
        "    learning_rate='adaptive',\n",
        "    max_iter=500,\n",
        "    random_state=42\n",
        ")\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "mlp_pred = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "models['MLP Regression'] = mlp_model\n",
        "results['MLP Regression'] = {\n",
        "    'R2': r2_score(y_test, mlp_pred),\n",
        "    'MSE': mean_squared_error(y_test, mlp_pred),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, mlp_pred)),\n",
        "    'MAE': mean_absolute_error(y_test, mlp_pred)\n",
        "}\n",
        "\n",
        "print(f\"MLP Regression - R¬≤: {results['MLP Regression']['R2']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Model Comparison and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive results DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df = results_df.sort_values('R2', ascending=False)\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(\"=\" * 50)\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Find the best model\n",
        "best_model_name = results_df.index[0]\n",
        "best_r2 = results_df.loc[best_model_name, 'R2']\n",
        "\n",
        "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
        "print(f\"   R¬≤ Score: {best_r2:.4f}\")\n",
        "print(f\"   RMSE: ${results_df.loc[best_model_name, 'RMSE']:,.2f}\")\n",
        "print(f\"   MAE: ${results_df.loc[best_model_name, 'MAE']:,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. R¬≤ Score Comparison\n",
        "axes[0, 0].bar(range(len(results_df)), results_df['R2'], color='skyblue', alpha=0.7)\n",
        "axes[0, 0].set_title('R¬≤ Score Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Models')\n",
        "axes[0, 0].set_ylabel('R¬≤ Score')\n",
        "axes[0, 0].set_xticks(range(len(results_df)))\n",
        "axes[0, 0].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. RMSE Comparison\n",
        "axes[0, 1].bar(range(len(results_df)), results_df['RMSE'], color='lightcoral', alpha=0.7)\n",
        "axes[0, 1].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Models')\n",
        "axes[0, 1].set_ylabel('RMSE ($)')\n",
        "axes[0, 1].set_xticks(range(len(results_df)))\n",
        "axes[0, 1].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. MAE Comparison\n",
        "axes[1, 0].bar(range(len(results_df)), results_df['MAE'], color='lightgreen', alpha=0.7)\n",
        "axes[1, 0].set_title('MAE Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Models')\n",
        "axes[1, 0].set_ylabel('MAE ($)')\n",
        "axes[1, 0].set_xticks(range(len(results_df)))\n",
        "axes[1, 0].set_xticklabels(results_df.index, rotation=45, ha='right')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Model Performance Heatmap\n",
        "metrics = ['R2', 'MSE', 'RMSE', 'MAE']\n",
        "heatmap_data = results_df[metrics].values\n",
        "im = axes[1, 1].imshow(heatmap_data, cmap='RdYlGn', aspect='auto')\n",
        "axes[1, 1].set_title('Performance Heatmap', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xticks(range(len(metrics)))\n",
        "axes[1, 1].set_xticklabels(metrics)\n",
        "axes[1, 1].set_yticks(range(len(results_df)))\n",
        "axes[1, 1].set_yticklabels(results_df.index)\n",
        "axes[1, 1].set_xlabel('Metrics')\n",
        "\n",
        "# Add colorbar\n",
        "plt.colorbar(im, ax=axes[1, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance Analysis (for tree-based models)\n",
        "if best_model_name in ['Decision Tree', 'Random Forest']:\n",
        "    print(f\"\\nFeature Importance Analysis for {best_model_name}:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    if best_model_name == 'Random Forest':\n",
        "        feature_importance = models[best_model_name].feature_importances_\n",
        "    else:  # Decision Tree\n",
        "        feature_importance = models[best_model_name].feature_importances_\n",
        "    \n",
        "    feature_names = features_to_use\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': feature_names,\n",
        "        'Importance': feature_importance\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "    \n",
        "    print(importance_df)\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(range(len(importance_df)), importance_df['Importance'], color='lightblue')\n",
        "    plt.yticks(range(len(importance_df)), importance_df['Feature'])\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.title(f'Feature Importance - {best_model_name}')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Model Predictions and Insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions from the best model\n",
        "if best_model_name == 'Polynomial Regression':\n",
        "    best_model, poly_features = models[best_model_name]\n",
        "    X_test_best = poly_features.transform(X_test_scaled)\n",
        "    best_predictions = best_model.predict(X_test_best)\n",
        "else:\n",
        "    best_model = models[best_model_name]\n",
        "    best_predictions = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Create a comparison DataFrame\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Actual': y_test.values,\n",
        "    'Predicted': best_predictions,\n",
        "    'Error': y_test.values - best_predictions,\n",
        "    'Error_Percentage': ((y_test.values - best_predictions) / y_test.values) * 100\n",
        "})\n",
        "\n",
        "print(f\"Sample Predictions using {best_model_name}:\")\n",
        "print(\"=\" * 60)\n",
        "print(comparison_df.head(10).round(2))\n",
        "\n",
        "print(f\"\\nPrediction Statistics:\")\n",
        "print(f\"Mean Absolute Error: ${comparison_df['Error'].abs().mean():,.2f}\")\n",
        "print(f\"Mean Absolute Percentage Error: {comparison_df['Error_Percentage'].abs().mean():.2f}%\")\n",
        "print(f\"Max Error: ${comparison_df['Error'].max():,.2f}\")\n",
        "print(f\"Min Error: ${comparison_df['Error'].min():,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize actual vs predicted values\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Scatter plot of actual vs predicted\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_test, best_predictions, alpha=0.6, color='blue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Credit Limit ($)')\n",
        "plt.ylabel('Predicted Credit Limit ($)')\n",
        "plt.title(f'Actual vs Predicted - {best_model_name}')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Residuals plot\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_test - best_predictions\n",
        "plt.scatter(best_predictions, residuals, alpha=0.6, color='green')\n",
        "plt.axhline(y=0, color='r', linestyle='--')\n",
        "plt.xlabel('Predicted Credit Limit ($)')\n",
        "plt.ylabel('Residuals ($)')\n",
        "plt.title(f'Residuals Plot - {best_model_name}')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Model Deployment and Usage\n",
        "\n",
        "The best performing model can now be used to predict credit card limits for new customers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to predict credit limit for new customers\n",
        "def predict_credit_limit(customer_data, model_name=None):\n",
        "    \"\"\"\n",
        "    Predict credit limit for a new customer\n",
        "    \n",
        "    Parameters:\n",
        "    customer_data: dict with keys matching features_to_use\n",
        "    model_name: specific model to use (if None, uses best model)\n",
        "    \n",
        "    Returns:\n",
        "    predicted_credit_limit: float\n",
        "    \"\"\"\n",
        "    if model_name is None:\n",
        "        model_name = best_model_name\n",
        "    \n",
        "    # Convert customer data to DataFrame\n",
        "    customer_df = pd.DataFrame([customer_data])\n",
        "    \n",
        "    # Apply the same preprocessing\n",
        "    # Education Level encoding\n",
        "    education_mapping = {\n",
        "        'Unknown': 0, 'Uneducated': 1, 'High School': 2, 'College': 3,\n",
        "        'Graduate': 4, 'Post-Graduate': 5, 'Doctorate': 6\n",
        "    }\n",
        "    customer_df['Education_Level'] = customer_df['Education_Level'].map(education_mapping)\n",
        "    \n",
        "    # Income Category encoding\n",
        "    income_mapping = {\n",
        "        'Unknown': 0, 'Less than $40K': 1, '$40K - $60K': 2, '$60K - $80K': 3,\n",
        "        '$80K - $120K': 4, '$120K +': 5\n",
        "    }\n",
        "    customer_df['Income_Category'] = customer_df['Income_Category'].map(income_mapping)\n",
        "    \n",
        "    # Marital Status encoding\n",
        "    marital_mapping = {\n",
        "        'Unknown': 0, 'Single': 1, 'Married': 2, 'Divorced': 3\n",
        "    }\n",
        "    customer_df['Marital_Status'] = customer_df['Marital_Status'].map(marital_mapping)\n",
        "    \n",
        "    # Fill any NaN values\n",
        "    customer_df = customer_df.fillna(0)\n",
        "    \n",
        "    # Scale the features\n",
        "    customer_scaled = scaler.transform(customer_df)\n",
        "    \n",
        "    # Make prediction\n",
        "    if model_name == 'Polynomial Regression':\n",
        "        model, poly_features = models[model_name]\n",
        "        customer_poly = poly_features.transform(customer_scaled)\n",
        "        prediction = model.predict(customer_poly)[0]\n",
        "    else:\n",
        "        model = models[model_name]\n",
        "        prediction = model.predict(customer_scaled)[0]\n",
        "    \n",
        "    return max(0, prediction)  # Ensure non-negative prediction\n",
        "\n",
        "# Example usage\n",
        "print(\"Example: Predicting credit limit for a new customer\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "example_customer = {\n",
        "    'Customer_Age': 35,\n",
        "    'Dependent_count': 2,\n",
        "    'Education_Level': 'Graduate',\n",
        "    'Income_Category': '$60K - $80K',\n",
        "    'Months_on_book': 24,\n",
        "    'Total_Relationship_Count': 4,\n",
        "    'Total_Trans_Amt': 2000,\n",
        "    'Marital_Status': 'Married'\n",
        "}\n",
        "\n",
        "predicted_limit = predict_credit_limit(example_customer)\n",
        "print(f\"Predicted Credit Limit: ${predicted_limit:,.2f}\")\n",
        "\n",
        "print(f\"\\nUsing the best model: {best_model_name}\")\n",
        "print(f\"Model R¬≤ Score: {best_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
